{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Contrastive-Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUFdo3wBPnKB",
        "outputId": "517c9641-79d9-412d-9e29-fe19aadfa06e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 14 12:03:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"hduclee\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"492488705804d86f275ac03c92debc85\" # key from the json file"
      ],
      "metadata": {
        "id": "xYy19Db6oN7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEhhzixLNJEG",
        "outputId": "be61e909-e12b-44b6-ec16-ce9e1352b70e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/drive/MyDrive/Vn-Legal-IRv2'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 71 (delta 31), reused 59 (delta 19), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n",
            "Submodule 'VnCoreNLP' (https://github.com/vncorenlp/VnCoreNLP.git) registered for path 'VnCoreNLP'\n",
            "Cloning into '/content/drive/MyDrive/Vn-Legal-IRv2/VnCoreNLP'...\n",
            "remote: Enumerating objects: 218, done.        \n",
            "remote: Counting objects: 100% (6/6), done.        \n",
            "remote: Compressing objects: 100% (6/6), done.        \n",
            "remote: Total 218 (delta 2), reused 1 (delta 0), pack-reused 212        \n",
            "Receiving objects: 100% (218/218), 214.22 MiB | 21.97 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n",
            "Submodule path 'VnCoreNLP': checked out '389d81e59a7bf27f445ccf5a87a348d6a52987aa'\n"
          ]
        }
      ],
      "source": [
        "!git clone --recurse-submodules https://hduc-le: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@github.com/hduc-le/Vn-Legal-IRv2.git /content/drive/MyDrive/Vn-Legal-IRv2/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d khanhdaom/datazalo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGs3_bTcnpSo",
        "outputId": "847aa2ca-93f2-4efc-d36f-931596068f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datazalo.zip to /content\n",
            " 99% 18.0M/18.2M [00:00<00:00, 27.6MB/s]\n",
            "100% 18.2M/18.2M [00:00<00:00, 30.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/datazalo.zip -d /content/drive/MyDrive/Vn-Legal-IRv2/raw_data/\n",
        "%cd /content/drive/MyDrive/Vn-Legal-IRv2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czhHKvWgn7qG",
        "outputId": "daf52809-a56d-4bbe-a56d-48816a2799d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Vn-Legal-IRv2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "_kLdfM75R7AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overall Configurations"
      ],
      "metadata": {
        "id": "1agPZfw5csKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = \"./raw_data\" #@param {type: 'string'}\n",
        "generated_data = \"./generated_data\" #@param {type: 'string'}\n",
        "word_segmenter = \"./VnCoreNLP/VnCoreNLP-1.1.1.jar\" #@param {type: 'string'}\n",
        "model_ckpt = \"./saved_model/model-cl\" #@param {type: 'string'}"
      ],
      "metadata": {
        "id": "lamhny4Mf790",
        "cellView": "form"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "vEiJdHymY4ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create legal data for reference\n",
        "\n",
        "Run cell below for starting preprocessing progress"
      ],
      "metadata": {
        "id": "z8Gkr3DOZPlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocessing.py --raw_data=$raw_data \\\n",
        "                        --legal_data=$generated_data\\"
      ],
      "metadata": {
        "id": "pbngklG9peX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e555f6c3-aa6a-428c-ce9c-0097682f8d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================\n",
            "Start create legal dict.\n",
            "Creating legal dict: 100% 3271/3271 [00:09<00:00, 349.24it/s]\n",
            "=====================\n",
            "Start create doc refer.\n",
            "=====================\n",
            "Created Doc Data.\n",
            "Created legal dictionary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create positive-pairs for contrastive training"
      ],
      "metadata": {
        "id": "Y4JttvNpZeUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We end up using the train questions and answers set for both contrastive learning and evaluation progress. The `train_ratio` is the ratio that we use for contrastive training, the remaining ratio of set will be used for evaluation later. Please define it and run cell below for starting to create pairs of training examples"
      ],
      "metadata": {
        "id": "03LiLmtcZlSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio=0.65 #@param {type: 'number'}\n",
        "!python create_pairs.py --raw_data=$raw_data\\\n",
        "                        --legal_data=$generated_data\\\n",
        "                        --train_ratio=$train_ratio\\\n",
        "                        --word_segmenter=$word_segmenter\\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN93LCp9IMdJ",
        "outputId": "78789220-448b-46cc-97dc-7449306126fd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Pairing the contrastive setences.\n",
            ">> Load Word-Segmenter...\n",
            "Pairing: 100% 2146/2146 [00:46<00:00, 46.05it/s]\n",
            "Created training pairs successfully.\n",
            "Created test questions-answers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "tXxNAKReY2d4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please choose the pretrained seq2seq model name or path. It might be your pretrained model or pretrained model from Huggingface.\n",
        "\n",
        "**Note**: The pretrained model should be an inheritence of PretrainedModel from Huggingface, should not be custom model."
      ],
      "metadata": {
        "id": "6RUcCr_GbCKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"vinai/bartpho-word\" #@param {type: 'string'}\n",
        "learning_rate = 5e-6 #@param {type: 'number'}\n",
        "lr_decay = True #@param {type: 'boolean'}\n",
        "batch_size = 4 #@param {type: 'number'}\n",
        "num_epochs = 10 #@param {type: 'number'}\n",
        "\n",
        "!python train_cl.py --paired_data=$generated_data \\\n",
        "                    --saved_model=$model_ckpt \\\n",
        "                    --model_name_or_path=$model_name_or_path \\\n",
        "                    --learning_rate=$learning_rate \\\n",
        "                    --lr_decay=$lr_decay \\\n",
        "                    --batch_size=$batch_size \\\n",
        "                    --num_epochs=$num_epochs \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usfe5sKqgfOF",
        "outputId": "256e4320-5a0d-4a63-ec36-fb3fc63c1d91",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Preparing paired data for contrastive learning.\n",
            ">> Download pretrained tokenizer\n",
            "Downloading: 100% 897/897 [00:00<00:00, 841kB/s]\n",
            "Downloading: 100% 874k/874k [00:00<00:00, 2.40MB/s]\n",
            "Downloading: 100% 1.08M/1.08M [00:00<00:00, 3.02MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            ">> Download pretrained model\n",
            "Downloading: 100% 1.57G/1.57G [00:26<00:00, 62.7MB/s]\n",
            "============= Start training =============\n",
            "Epoch 0: 100% 537/537 [09:34<00:00,  1.07s/it, loss=0.0629]\n",
            ">> Finished epoch 0.\n",
            ">> Epoch loss: 29.09632\n",
            "Epoch 1: 100% 537/537 [09:32<00:00,  1.07s/it, loss=0.000216]\n",
            ">> Finished epoch 1.\n",
            ">> Epoch loss: 10.66461\n",
            "Epoch 2: 100% 537/537 [09:38<00:00,  1.08s/it, loss=0.00224]\n",
            ">> Finished epoch 2.\n",
            ">> Epoch loss: 9.94321\n",
            "Epoch 3: 100% 537/537 [09:30<00:00,  1.06s/it, loss=0.00274]\n",
            ">> Finished epoch 3.\n",
            ">> Epoch loss: 8.55409\n",
            "Epoch 4: 100% 537/537 [09:38<00:00,  1.08s/it, loss=0.000212]\n",
            ">> Finished epoch 4.\n",
            ">> Epoch loss: 7.52371\n",
            "Epoch 5: 100% 537/537 [09:29<00:00,  1.06s/it, loss=0.000376]\n",
            ">> Finished epoch 5.\n",
            ">> Epoch loss: 8.45827\n",
            "Epoch 6: 100% 537/537 [09:38<00:00,  1.08s/it, loss=0.000846]\n",
            ">> Finished epoch 6.\n",
            ">> Epoch loss: 6.17157\n",
            "Epoch 7: 100% 537/537 [09:29<00:00,  1.06s/it, loss=0.000665]\n",
            ">> Finished epoch 7.\n",
            ">> Epoch loss: 6.23195\n",
            "Epoch 8: 100% 537/537 [09:38<00:00,  1.08s/it, loss=0.00184]\n",
            ">> Finished epoch 8.\n",
            ">> Epoch loss: 6.06605\n",
            "Epoch 9: 100% 537/537 [09:27<00:00,  1.06s/it, loss=0.000193]\n",
            ">> Finished epoch 9.\n",
            ">> Epoch loss: 5.10539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "PAQdV8rqY0CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"./saved_model/model-cl\" #@param {type: 'string'}\n",
        "batch_size = 64 #@param {type: 'number'}\n",
        "pooling_output = True #@param {type: 'boolean'}\n",
        "eval_option = \"select evaluation mode\" #@param [\"full_id\", \"law_id\"] {allow-input: true}\n",
        "\n",
        "!python evaluation.py --legal_data=$generated_data \\\n",
        "                    --model_name_or_path=$model_checkpoint \\\n",
        "                    --tokenizer_name_or_path=$model_checkpoint\\\n",
        "                    --word_segmenter=$word_segmenter \\\n",
        "                    --batch_size=$batch_size \\\n",
        "                    --pooling_output=$pooling_output \\\n",
        "                    --eval_mode=$eval_option \\"
      ],
      "metadata": {
        "id": "xswy0ZOLbkzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "2d974dcb-4c0c-4505-e8e6-5f26d7b2aae8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Prepare data for evaluation\n",
            ">> Load Word-Segmenter...\n",
            ">> Load pretrained model...\n",
            ">> Load pretrained tokenizer...\n",
            ">> Encode legal docs for reference\n",
            "Processing: 100% 960/960 [43:07<00:00,  2.69s/it]\n",
            ">> Load Queries\n",
            "Loading: 100% 1119/1119 [00:00<00:00, 592679.15it/s]\n",
            "Number of queries: 1119\n",
            "============== Start Evaluation ==============\n",
            "Processing: 100% 35/35 [00:42<00:00,  1.21s/it]\n",
            "Corpus Chunks:   0%|          | 0/62 [00:00<?, ?it/s]\n",
            "Queries: 1119\n",
            "Corpus: 61425\n",
            "Score-Function: cos_sim\n",
            "\n",
            "-------- Accuracy ---------\n",
            "Accuracy@1: 53.98%\n",
            "Accuracy@3: 72.83%\n",
            "Accuracy@5: 78.91%\n",
            "Accuracy@10: 85.17%\n",
            "-------- Precision ---------\n",
            "Precision@1: 53.98%\n",
            "Precision@3: 24.78%\n",
            "Precision@5: 16.25%\n",
            "Precision@10: 8.83%\n",
            "-------- Recall ---------\n",
            "Recall@1: 53.26%\n",
            "Recall@3: 73.09%\n",
            "Recall@5: 79.77%\n",
            "Recall@10: 86.43%\n",
            "-------- F2 Score ---------\n",
            "f2-score@1: 53.34%\n",
            "f2-score@3: 52.45%\n",
            "f2-score@5: 44.62%\n",
            "f2-score@10: 31.23%\n",
            "-------- MRR ---------\n",
            "MRR@1: 0.5398\n",
            "MRR@3: 0.6236\n",
            "MRR@5: 0.6376\n",
            "MRR@10: 0.6461\n",
            "-------- NDCG ---------\n",
            "NDCG@10: 0.7013\n",
            "-------- Average Precision ---------\n",
            "MAP@1: 0.5398\n",
            "MAP@3: 0.6271\n",
            "MAP@5: 0.6441\n",
            "MAP@10: 0.6536\n"
          ]
        }
      ]
    }
  ]
}